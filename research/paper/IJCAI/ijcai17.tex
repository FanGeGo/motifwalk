%%%% ijcai17.tex

\typeout{Motif-Aware Graph Embeddings}

% These are the instructions for authors for IJCAI-17.
% They are the same as the ones for IJCAI-11 with superficical wording
%   changes only.


\documentclass{article}
% The file ijcai17.sty is the style file for IJCAI-17 (same as ijcai07.sty).
\usepackage{ijcai17}
\usepackage{amsthm}
\usepackage{amssymb}
% Use the postscript times font!
\usepackage{times}

% the following package is optional:
%\usepackage{latexsym} 

% Following comment is from ijcai97-submit.tex:
% The preparation of these files was supported by Schlumberger Palo Alto
% Research, AT\&T Bell Laboratories, and Morgan Kaufmann Publishers.
% Shirley Jowell, of Morgan Kaufmann Publishers, and Peter F.
% Patel-Schneider, of AT\&T Bell Laboratories collaborated on their
% preparation.

% These instructions can be modified and used in other conferences as long
% as credit to the authors and supporting agencies is retained, this notice
% is not changed, and further modification or reuse is not restricted.
% Neither Shirley Jowell nor Peter F. Patel-Schneider can be listed as
% contacts for providing assistance without their prior permission.

% To use for other conferences, change references to files and the
% conference appropriate and use other authors, contacts, publishers, and
% organizations.
% Also change the deadline and address for returning papers and the length and
% page charge instructions.
% Put where the files are available in the appropriate places.

\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]

\title{Motif-Aware Network Embeddings}

\author{Anonymous authors}

\begin{document}

\maketitle

\begin{abstract}
  In this paper, we propose a deep convolutional network model for
  the unsupervised and semi-supervised graph embedding task. Our 
  model employs the higher-order organization (i.e. motifs) 
  of complex networks, and injects the higher-order connectivity 
  patterns into each layer in a deep graph convolutional networks. 
  We demonstrate our results on node labels classification, link 
  prediction, and t-SNE visuallization.
\end{abstract}

\section{Introduction}

\subsection{Complex network and machine learning}

Network modeling have been an essential tool for a wide
range of scientific fields \cite{physicnet,molecule,youtube,motifblockmilo,juremotif}.
The network science view usually reveals the underlying structure 
of a complex system. Based on the system's network structure, 
scientists can make predictions and explaination
about the system's behavior. For example, in biology, the
study on neuronal systems connectivity indicated
that the component arrangement of a neural system is optimized
for short processing paths rather than wiring lengths \cite{kaiser2006nonoptimal}. 
Similarly, social networks analysis provides communities structures
as well as social interaction patterns \cite{west2014exploiting,barabasi2014network}. 
However, along with the information explosion, the large graph-structured
data poses a great challenge for traditional network analysis methods
in term of scalability and complexity. To deal with such challendges,
one promising approach is to apply machine learning methods (especially
deep learning) methods to network problems.

Bridging the gap between network science and machine learning
is also a challenging task. Due to the irregularity in network and 
graph-structured data, it is desirable to have a \emph{meaningful}
and structural network representation for machine learning application. 
Traditionally, vector representation can be obtained via graph spectral methods.
However, spectral methods are shown to be unscalable without estimation
methods TODO: find theoretical citation \cite{deepwalk,node2vec}.
Recently, inspired by the skipgram model in natural language processing
\cite{skipgram}, \citeauthor{deepwalk} propsed their scalable graph
embedding algorithm named DeepWalk. Their results node classification
proved the effectiveness of their algorithm in learning a lower dimensionality 
representation of a complex network. Subsequence works to DeepWalk
further improved node classification accuracy by modifying graph 
context generation process \cite{line,grarep,node2vec}. On the other
hand, more direct (and more effective) approaches were proposed in
\cite{planetoid,gcn}. Instead of learning the network representation
using only network structure (e.g. adjacency matrix), \citeauthor{planetoid}
proposed to injects the known labeling and node feature into the
representation learning process. \citeauthor{gcn} further improved
results from planetoid \cite{planetoid} by applying graph convolution
technique in their deep network model. These aforementioned approaches 
are similar in the sense that they all learn a latent representation 
of a complex network from data, then use this representation to solve 
a network problem using various machine learning tools. 

\subsection{Motif in complex network}

There are three scale of network analysis: macroscopic, mesoscopic, 
and microscopic. The macroscopic scale displays a network as a whole to
study its robustness \cite{callaway2000network} or dynamics TODO: find citation \cite{barabasi2014network}.
In contrast, the microscopic scale studies the pair-wise interactions
between nodes in a network which is specific to the given system
TODO: find citation \cite{physicnet}. On the other hand, the mesoscopic
scale is an intermediate in which we consider the network is a composition of
subgraphs. In many research, especially computational biology, the
mesoscopic components are called \emph{motifs}, and it is common
to think of them as building blocks for a complex system \cite{motifblockmilo}.

\begin{definition}{\emph{Network motif}}
Given a graph $G = {V,E}$, define a subgraph $G' = {V', E'}$ with $V' \subseteq V$;
$E' \subset E$ s.t. $i,j \in V' \forall e_{ij} \in E'$ and $|V'| \ll |V|$. Recurring subgraphs
are called \emph{network motif} when they are statistically significant.
\end{definition}

Also refered as higher-order organization by \citeauthor{juremotif}, network motifs
are believed to represent the underlying mechanism of a complex system \cite{netmotif,alon2006introduction,mangan2003structure}. 
For instance, the directional bi-fan motif TODO: figure
and its simplified undirectional version TODO: figure are crucial in a citation network. 
Beside having a statistical significance, bi-fan motif is also intuitively 
sensible in citation network as it represents the citation mechanism as an activity
in a subgraph. The correlation of recurring subgraphs and system functionality has 
been studied extensively in biological systems such as 
transcription networks \cite{mangan2003structure} and brain 
networks \cite{brainnetheuvel,honey2007network}. As networks motifs
have been recognized as the fundamental building block of a complex
systems, using them as a strucutural guidance for machine learning
on graph data can yield possitive improvements.


\section{Methods}

In this section, we present our general approach of using
motif co-occurrence matrix as

\subsection{Motif laplacian}

Present laplacian and power of laplacian of graph.
Present motif types and laplacian for each type.
Algorithms and estimation techniques.

\subsection{Graph convolutional architecture}

Present graph convolutional and estimation technique.
Present renormalization trick and GCN.
Present using motif types between graph layers.

\subsection{Unsupervised graph motif auto-encoder}

Architecture for auto-encoder.

\subsection{Semi-supervised node labeling}

Architecture for node labeling.

\section{Experiments}

\subsection{Datasets and observations}

\subsection{Motif significance}

\subsection{Architectures}

\section{Results}

\subsection{Unsupervised}

Traditional task on blogcatalog and others.
Link prediction.
t-SNE.

\subsection{Semi-supervised}

Task on featured networks.

\section{Related work}

\subsection{Spectral approaches}

\subsection{Skipgram-based approaches }

\subsection{Deep neural network approaches}

\section{Discussion}

Our paper's contributions are proposing an extension to the graph convolutional 
architecture; proposing the uses and demonstrate the importance of motifs in
real worldnetworks.

Limitation: 

\subsection{Layout}

Print manuscripts two columns to a page, in the manner in which these
instructions are printed. The exact dimensions for pages are:
\begin{itemize}
\item left and right margins: .75$''$
\item column width: 3.375$''$
\item gap between columns: .25$''$
\item top margin---first page: 1.375$''$
\item top margin---other pages: .75$''$
\item bottom margin: 1.25$''$
\item column height---first page: 6.625$''$
\item column height---other pages: 9$''$
\end{itemize}

All measurements assume an 8-1/2$''$ $\times$ 11$''$ page size. For
A4-size paper, use the given top and left margins, column width,
height, and gap, and modify the bottom and right margins as necessary.

\subsection{Format of Electronic Manuscript}

For the production of the electronic manuscript, you must use Adobe's
{\em Portable Document Format} (PDF). A PDF file can be generated, for
instance, on Unix systems using {\tt ps2pdf} or on Windows systems
using Adobe's Distiller. There is also a website with free software
and conversion services: {\tt http://www.ps2pdf.com/}. For reasons of
uniformity, use of Adobe's {\em Times Roman} font is strongly suggested. In
\LaTeX2e{}, this is accomplished by putting
\begin{quote} 
\mbox{\tt $\backslash$usepackage\{times\}}
\end{quote}
in the preamble.\footnote{You may want also to use the package {\tt
latexsym}, which defines all symbols known from the old \LaTeX{}
version.}
  
Additionally, it is of utmost importance to specify the American {\bf
letter} format (corresponding to 8-1/2$''$ $\times$ 11$''$) when
formatting the paper. When working with {\tt dvips}, for instance, one
should specify {\tt -t letter}.

\subsection{Title and Author Information}

Center the title on the entire width of the page in a 14-point bold
font. Below it, center the author name(s) in a 12-point bold font, and
then center the address(es) in a 12-point regular font. Credit to a
sponsoring agency can appear on the first page as a footnote.

\subsubsection{Blind Review}

In order to make blind reviewing possible, authors must omit their
names and affiliations when submitting the paper for review. In place
of names and affiliations, provide a list of content areas. When
referring to one's own work, use the third person rather than the
first person. For example, say, ``Previously,
Gottlob~\shortcite{gottlob:nonmon} has shown that\ldots'', rather
than, ``In our previous work~\cite{gottlob:nonmon}, we have shown
that\ldots'' Try to avoid including any information in the body of the
paper or references that would identify the authors or their
institutions. Such information can be added to the final camera-ready
version for publication.

\subsection{Abstract}

Place the abstract at the beginning of the first column 3$''$ from the
top of the page, unless that does not leave enough room for the title
and author information. Use a slightly smaller width than in the body
of the paper. Head the abstract with ``Abstract'' centered above the
body of the abstract in a 12-point bold font. The body of the abstract
should be in the same font as the body of the paper.

The abstract should be a concise, one-paragraph summary describing the
general thesis and conclusion of your paper. A reader should be able
to learn the purpose of the paper and the reason for its importance
from the abstract. The abstract should be no more than 200 words long.

\subsection{Text}

The main body of the text immediately follows the abstract. Use
10-point type in a clear, readable font with 1-point leading (10 on
11).

Indent when starting a new paragraph, except after major headings.

\subsection{Headings and Sections}

When necessary, headings should be used to separate major sections of
your paper. (These instructions use many headings to demonstrate their
appearance; your paper should have fewer headings.)

\subsubsection{Section Headings}

Print section headings in 12-point bold type in the style shown in
these instructions. Leave a blank space of approximately 10 points
above and 4 points below section headings.  Number sections with
arabic numerals.

\subsubsection{Subsection Headings}

Print subsection headings in 11-point bold type. Leave a blank space
of approximately 8 points above and 3 points below subsection
headings. Number subsections with the section number and the
subsection number (in arabic numerals) separated by a
period.

\subsubsection{Subsubsection Headings}

Print subsubsection headings in 10-point bold type. Leave a blank
space of approximately 6 points above subsubsection headings. Do not
number subsubsections.

\subsubsection{Special Sections}

You may include an unnumbered acknowledgments section, including
acknowledgments of help from colleagues, financial support, and
permission to publish.

Any appendices directly follow the text and look like sections, except
that they are numbered with capital letters instead of arabic
numerals.

The references section is headed ``References,'' printed in the same
style as a section heading but without a number. A sample list of
references is given at the end of these instructions. Use a consistent
format for references, such as that provided by Bib\TeX{}. The reference
list should not include unpublished work.

\subsection{Citations}

Citations within the text should include the author's last name and
the year of publication, for example~\cite{gottlob:nonmon}.  Append
lowercase letters to the year in cases of ambiguity.  Treat multiple
authors as in the following examples:~\cite{abelson-et-al:scheme}
or~\cite{bgf:Lixto} (for more than two authors) and
\cite{brachman-schmolze:kl-one} (for two authors).  If the author
portion of a citation is obvious, omit it, e.g.,
Nebel~\shortcite{nebel:jair-2000}.  Collapse multiple citations as
follows:~\cite{gls:hypertrees,levesque:functional-foundations}.
\nocite{abelson-et-al:scheme}
\nocite{bgf:Lixto}
\nocite{brachman-schmolze:kl-one}
\nocite{gottlob:nonmon}
\nocite{gls:hypertrees}
\nocite{levesque:functional-foundations}
\nocite{levesque:belief}
\nocite{nebel:jair-2000}

\subsection{Footnotes}

Place footnotes at the bottom of the page in a 9-point font.  Refer to
them with superscript numbers.\footnote{This is how your footnotes
should appear.} Separate them from the text by a short
line.\footnote{Note the line separating these footnotes from the
text.} Avoid footnotes as much as possible; they interrupt the flow of
the text.

\section{Illustrations}

Place all illustrations (figures, drawings, tables, and photographs)
throughout the paper at the places where they are first discussed,
rather than at the end of the paper. If placed at the bottom or top of
a page, illustrations may run across both columns.

Illustrations must be rendered electronically or scanned and placed
directly in your document. All illustrations should be in black and
white, as color illustrations may cause problems. Line weights should
be 1/2-point or thicker. Avoid screens and superimposing type on
patterns as these effects may not reproduce well.

Number illustrations sequentially. Use references of the following
form: Figure 1, Table 2, etc. Place illustration numbers and captions
under illustrations. Leave a margin of 1/4-inch around the area
covered by the illustration and caption.  Use 9-point type for
captions, labels, and other text in illustrations.

\section*{Acknowledgments}

The preparation of these instructions and the \LaTeX{} and Bib\TeX{}
files that implement them was supported by Schlumberger Palo Alto
Research, AT\&T Bell Laboratories, and Morgan Kaufmann Publishers.
Preparation of the Microsoft Word file was supported by IJCAI.  An
early version of this document was created by Shirley Jowell and Peter
F. Patel-Schneider.  It was subsequently modified by Jennifer
Ballentine and Thomas Dean, Bernhard Nebel, and Daniel Pagenstecher.
These instructions are the same as the ones for IJCAI--05, prepared by
Kurt Steinkraus, Massachusetts Institute of Technology, Computer
Science and Artificial Intelligence Lab.

\appendix

\section{\LaTeX{} and Word Style Files}\label{stylefiles}

The \LaTeX{} and Word style files are available on the IJCAI--17
website, {\tt http://www.ijcai-17.org/}.
These style files implement the formatting instructions in this
document.

The \LaTeX{} files are {\tt ijcai17.sty} and {\tt ijcai17.tex}, and
the Bib\TeX{} files are {\tt named.bst} and {\tt ijcai17.bib}. The
\LaTeX{} style file is for version 2e of \LaTeX{}, and the Bib\TeX{}
style file is for version 0.99c of Bib\TeX{} ({\em not} version
0.98i). The {\tt ijcai17.sty} file is the same as the {\tt
ijcai07.sty} file used for IJCAI--07.

The Microsoft Word style file consists of a single file, {\tt
ijcai17.doc}. This template is the same as the one used for
IJCAI--07.

These Microsoft Word and \LaTeX{} files contain the source of the
present document and may serve as a formatting sample.  

Further information on using these styles for the preparation of
papers for IJCAI--17 can be obtained by contacting {\tt
pcchair@ijcai-17.org}.

%% The file named.bst is a bibliography style file for BibTeX 0.99c
\bibliographystyle{named}
\bibliography{ijcai17}

\end{document}

