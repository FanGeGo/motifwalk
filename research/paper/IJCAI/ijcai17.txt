Reply to Review #26292

Thank you very much for your comprehensive comments for our paper. The main idea of our paper is to show that some knowledge about a complex network (the main motif) can be exploited to improve various machine learning algorithms. To be clear, our pipeline in this paper contains two steps: Motif discovery -> Machine learning applications on networks. As we addressed in our paper, the main bottle-neck is the process of motif discovery, which can be made much faster by random sampling. For the running time of motifwalk and m-GCN (given a motif), our running time is the same as other state-of-the-art algorithms, while the performance is better. About your comments on our experimental network size, we admit that the network size is not particularly large. However, these networks are the standard benchmark (used in Deepwalk, GCN, node2vec). A further experiment on truly large networks (several millions of nodes, billions of edges) is desirable, but it is more of an implementation challenge (memory management for m-GCN and distributed computation for motifwalk) than a new idea. Besides, please understand that because of the limited number of pages, we cannot contain all related concepts in our paper.

To answer your further remarks:

The pseudo code of Algorithms 1 and 2 should be better explained (also in the main text). Algorithm 1 appears very far from its first use and is never explained in the text. For the input parameters, the type should be explained.
- According to your suggestion, we will add some type annotation to our algorithm 1 and 2.

P1C1 "To deal with such challenges, one promising approach is to apply machine learning (especially deep learning)" Can you give references for this statement? This is the first time that I have heard of deep learning being used as a tool for obtaining fast algorithms for network analysis.
- (Perozzi, 2014), (Yang, 2015) and (Kipf, 2017) are some of the examples where modern machine learning algorithms are used to learn predictive models on networks/graphs. Following your suggestions, we will add these references to the sentence.

P1C2 "is a composition" => "as a composition"
- Thank you very much for pointing out the typo.

P1C2 "Recurring subgraph ... when they are statistically significant." This is a sloppy formulation: what means statistically significant for a subgraph (we need to talk about a null model and about counting the number of subgraphs). Most network motif algorithms actually search for motifs that are "induced" subgraphs (i.e. only induced subgraphs of the network and the random model are counted). Can you comment on why you are considering all subgraphs?
- The term "statistically significant" refers to the statistical test of a motif on a network. The reason we are considering all subgraphs instead of induced subgraphs is: structures that do not appear in the network can also be tested. Let's say graph G1 has induced subgraph M, while M does not appear in another graph G2. In this case, if we only consider induced subgraphs, we perform the statistical test of M on G1, but we don't perform the same test on G2. In practice, if M is significant in network G1 (large z-score) and M also has large z-score on G2, we can argue about the structural and functional similarity between G1 and G2. The absence of a certain subgraph is also valuable information in motif analysis.

P2C1 "Spectral Clustering .... shown to be unscalable" These are very strong claims and spectral clustering has been applied to networks that are much larger than the ones used in this work. I would probably be a bit more cautious here.
- We understand the fact that our experiments haven't shown the advantage of our algorithms in term of run time. However, the runtime of our algorithms is comparable to the state-of-the-art algorithms and far below spectral clustering. Besides, the fact that spectral clustering runs in O(n^3) (and O(m*n^2) using k-means) is well-known, and the scalability problem of spectral methods, as well as matrix factorization methods, has been addressed in many recent researches (Perozzi, 2014). As a matter of fact, most of the published techniques on graph embedding which are based on matrix factorization only runs on several thousand of nodes at most.

P2C2 Explain what the Skip-gram model is.
- Skip-gram model (Mikolov, 2013), or commonly known by its implementation word2vec, is an auto-encoder to learn the vector representation of words from the text.

P2C2 "Computing the normalization factor remains intractable" Could you be more specific here?
- The pair-wise potential is easy to compute as it is a dot product of two vectors, but to compute the dot product of a vector with all other vectors (normalization) is more costly. I have cited the papers (Pereozzi, 2014) and (Grover, 2016) that addressed this problem.

P3C1 It is completely unclear what theta and Lambda are here? (The frequencies of which graph?) Also, one should define what the graph Laplacian is.
- Theta parameterizes the filter g, whose wavelet basis is given by the graph Laplacian. Graph Laplacian L = D - A, where D = diag(row_sum(A)), A is the adjacency matrix. These definitions can be found in our cited papers. We will include further explanations into our paper.

P3C1 What is "\lambda_max"?
- \lambda_max is the largest eigenvalue of the graph Laplacian. In the context here, \lambda_max matters because it affects the accuracy of our linear approximation. However, as pointed out by (Kipf, 2017), the neural network can adapt to the value of \lambda_max, and we can formulate the linear approximation assuming \lambda_max = 2.

P3C1 What is "X"?
- In this context, X is a matrix contains the features of each node. For example, in a citation network, there are connections between papers (citation) and a tf-idf feature matrix X of each node. In graph information processing context, X is a matrix containing discrete signal vector on each node.

P3C2 What does it mean that "(i,j) satisfies A"?
- A is a set of anchor nodes. Please look at Figure 3, we demonstrated the rule to select anchor nodes. Basically, what we want to say here is: if node i and node j belongs to the motif M, and their positions satisfy description in A, the value of motif matrix index (i,j) is set to 1.

P3C2 Please define cut. What is an anchor node? What is \chi_A?
- We will include the definition of graph cut and \chi_A if possible. Basically, \chi_A is the anchor nodes.

P4C1 The null model used here is different from the common ones that do not only assume that the number of edges and nodes are the same, but they also assume that the degree distribution is the same.
- Thank you for your note here. Experiments with different null models are one of our future work.

P4C1 Figure 2 has only "m3-8" and "m3-9"
- Many other uninteresting motifs having low z-score are omitted from Figure 4.

P4C1 What are the "frequencies" of the "motif network"?
- This is an analog to the frequency domain in the context of Fourier transformation. What we mean here is the wavelet basis defined by our constructed motif network.

P4C2 What is "theta'"?
- We have answered this question above at the first P3C1 question.

P5C1 In Algorithm 2, G and G_m should not have the same vertex and edge set. What is the motif graph G_m?
- Thank you for pointing our this typo. G_m have the same vertex set as G, but not the edge set. The motif graph is a graph constructed from the original graph where nodes are connected if they belong to the same motif (with respect to anchor nodes). Figure 3 demonstrates this idea.

P5C2 "In the previous section" Section 3.2 does not talk about graph convolutions. As a general remark: The structure of the paper is quite confusing, there is to much jumping between the motif part and the convolutional network part.
- Thank you for your comment here. Since we want to define the convolutional using a basis defined by network motif, we have to put two sections next to each other.

P6C1 What is the skip-gram window size?
- Skip-gram window size is one hyper-parameter of a skip-gram model. This hyper-parameter controls the context scope. Please check (Mikolov, 2013) or (Perozzi, 2014) for more detail. We omitted the detail of such parameter because of the limited number of pages.

P6C2 "This limitation is due to the large networks that we experimented" The networks are really not that large, I would rephrase this sentence.
- Thank you for your comment. We will provide possible rephrase for the future. On a side note, for full motif analysis (computing z-score), our experimented networks are substantial. (Benson, 2016) (published in Science) is a reference to the current limit of motif analysis. In practice, the step of analyzing motifs can be replaced by a much faster random sampling process. However, as mentioned above, our main objective of this paper isn't motif analysis.

Lastly, we would like to sincerely thank you for your time reviewing our paper and all of your thoughtful comments above.

=========================================

Reply to Review #27278

First of all, thank you very much for your time and your recognition of our novelty. Your 5 steps summarization is exactly what we have done. Secondly, we answer the questions you have given us:

1. How the selected significant motif helps on improving the node representation learning? The accuracy improves because nodes in motif can be better classified?
- Our motif method can be viewed as n-order (n=2,3,4,...) proximity. Take Figure 3 as an example. Although there might be no connection between two yellow nodes in the network, in the motif network (represented by motif matrix), these two nodes are connected. We hope it makes sense to say that, in the case of citation network, two papers which cite the same papers are similar even-though they do not directly cite each other. Such underlying mechanism in other networks is encoded in the motif structures. Therefore, by using motif matrix as the "same motif" indicator, we help the algorithm to know that these nodes must be similar.

2. Why selecting only one motif? Not several motifs? Figure 4 shows that in a network, there can exist several motifs that have high z-score.
- We have not yet come up with a way to use several motifs in our algorithms. Experimental results consistently showed no or negative improvement with naive approaches to use more than one motif. One of our future work direction is to understand z-score, null models, and using multiple motifs.

3. Comparing to GCN, m-GCN has better accuracy, but not always and not very significant improvement (Table 5, m-GCN (rand.splits)). In Evaluation, why using F1 for the comparison of Motifwalk with other baselines, but Accuracy for the comparison of m-GCN with other baselines? Both performance measure scores should be reported for the comparison of m-GCN.
- We admit that we should make it more clear and uniform in our experiments. F1-score is employed mainly because of the BlogCatalog dataset. In this dataset, a node can have multiple labels and some labels only have 9 instances while others have hundred. Such skew in the dataset was the main reason for us to use F1-score for the unsupervised learning task. Furthermore, for the unsupervised learning task, F1-score is used in previous researches; hence we think it might be easier for comparison. For semi-supervised learning task, the comparison is done using accuracy because there were no skew in the dataset (and also for easier comparison).

Other detailed comments:

1. “U_m from equation (7)”, there is no U_m in equation (7)
- We are very sorry for this typo; we meant equation (6).

2. need formal definition of motif graph G_m
- We understood, we will make Algorithms 1 and Definition 2.1 clear by adding that they refer to G_m.

3. “there is two network contexts” – there are
- Thank you very much for pointing out the typo.

4. Check table 1 and 2, the data sets statistics of BlogCatelog, Citeseer, and Cora.  Citeseer in Table 2 are the same as BlogCatelog in Table 1? But different from Citeseer in Table 1? But Cora in Table 2 is similar to Citeseer in Table 1?
- We are terribly sorry for this typo; there was a mistake in data entry for the first two rows. It should be Citeseer: nodes:3,327 edges:4,732 classes:6 features:3,703; and Cora: nodes:2,708 edges:5,429 classes:7 features:1,433. We have fixed the typo.

We would like to say thank you very much for your time spent on reviewing our papers. Thank you again for pointing out the typo in Table-2.

=========================================

Reply to Review #32319

Thank you very much for your comments and your recognition of our contents. Following your suggestions, here are our answers:

1. Section 3.1 doesn't mention the method for motif counting nor references to the method used.
- Thank you very much for pointing out this lack of contents. We will add the citation for ESU algorithm (Wernicke, 2006) into this session. We will also include citation for the randomization method (configuration model) used to compute the z-score.

2. The analysis is very short and provides very little insight on how good the proposed method is.
- We admit that our writing style of conclusion and analysis made it unclear of how good our method is. We will add more thorough analysis on the experimental results and some insight of why our algorithms work. In general, our motif method can be viewed as an n-order (n=2,3,4,...) proximity. Take Figure-3 as an example. Although there might be no connection between two yellow nodes in the network, in the motif network (represented by motif matrix) these two nodes are connected. We hope it makes sense to say that, in the case of citation network, two papers which cite the same papers are similar even though they do not directly cite each other. Such underlying mechanism in other networks is encoded in the motif structures. Therefore, by using motif matrix as the "same motif" indicator, we help the algorithm to know that these nodes must be similar. Another point to be added is that our results agree with insights from (Benson, 2016), which was published in Science.

3. There is no type of parameter sensitivity analysis on any of the used parameters.
- While m-GCN doesn't have any hyper-parameter to tune, we admit that motifwalk has many. Since the parameters of skip-gram model are well studied in previous researches, we will add the citation for those hyper-parameters. For our part, we will add the discussion of our newly introduced hyper-parameter "nmwalk". This parameter controls how much "motif information" is injected to the graph context.

4. (in Section 6) Motif analyzing method can perform poorly in terms of runtime since the calculation of motifs is heavy, but the authors provide no analysis to evaluate the scale of this weakness.
- We will change our conclusion to make it clear that motif analysis can be the bottleneck, but we can overcome it using randomized algorithms (we will add the references to such algorithms - for example RAND-ESU). More importantly, we will emphasize that the bottleneck is at motif analysis, not our proposed algorithms motifwalk and m-GCN. Thank you very much for pointing this ambiguity.

Lastly, please understand for us that given limited number of content pages, we have tried our best to make our idea clear with the cost of further discussion and investigation of our parameters. We sincerely thank you again for your time and valuable comments on our paper.

=========================================

Reply to Review  #32325

Thank you very much for your comments and recognition of our method. We answer some of your comments as follow:

1. While reading this paper, especially in the first part it was ambiguous wether the authors perform node or graph embedding, that is, learning representations for each node or for the whole graph.
- Thank you very much for pointing out such ambiguity. We will emphasize that we do node embedding (similar to node2vec) in our paper.

2. Most of the concepts are densely written and the trouble in definitions.
- We understand that the content of this paper is quite dense due to the fact that we need to explain many concepts building up our method. We will revise our structures and phrasing.

3. Section 2 (Related work) expands to aspects of the main methodology.
- We have done our best to present all related researches that our methods were built upon in this section. We truly hope that you would reconsider this point.

4. Lack of parameter sensitivity analysis.
- Thank you very much for pointing out this problem. We will add the parameters analysis for our motifwalk algorithm and emphasize that we only have to tune one hyper-parameter (nmwalk) in comparison to two hyper-parameter in node2vec.

5. It would be nice to have the performance on graph classification.
- This is a wonderful point to add to our paper. If there is available space, we will add method and experimental results for graph classification. Thank you very much for this suggestion.

6. The term "Multi-class Linear Regression" is confusing.
- With this term, we want to refer to the classification of nodes with many possible classes and we assign each node to only one class. We will add this explanation in the caption of the tables.

7. Which classification method was used to obtain the results on tables 4 and 5?
- Table 4 presented the unsupervised learning task, in which we used the learned embeddings and labels to train a Multi-class multi-label linear regression model (one-versus-rest). We use sklearn for such task. Table 5 presented the classification result for label prediction using a neural network (m-GCN) with softmax output. We will add these details into our paper as you suggested.

We really appreciate the time you have spent on reviewing and giving us your comments. Thank you very much for your time.
